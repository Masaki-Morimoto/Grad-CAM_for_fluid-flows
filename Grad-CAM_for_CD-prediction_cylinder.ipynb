{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM for $C_D$ prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: M. Morimoto (Keio University, Japan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masaki Morimoto provides no guarantees for this code. Use as-is and for academic research use only; no commercial use allowed without permission. For citations, please use the reference below:\n",
    "\n",
    "Ref: Masaki Morimoto, Kai Fukami, Kai Zhang, and Koji Fukagata, \"Generalization techniques of neural networks for fluid flow estimation,\" arXiv:2011.11911 (2020).\n",
    "The code is written for educational clarity and not for speed.\n",
    "\n",
    "-- version 1: Feb 3, 2021\n",
    "For performing Grad-CAM, the user has to install 'keras', 'numpy', 'pandas' and 'cv2'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Codes & problem setting\n",
    "\n",
    "K. Fukami, K. Fukagata, and K. Taira, \"Assessments of supervised machine learning for fluid flows,\" Theor. Comput. Fluid Dyn., 34(4), pp.497--519, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] Cylinder DNS (immersed boundary method)\n",
    "\n",
    "H. Kor, M. Badri Ghomizad, and K. Fukagata. \"A unified interpolation stencil for ghost-cell immersed boundary methodfor flow around complex geometries,\" J. Fluid Sci. Technol., 12(1):JFST0011, 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] Referenced link (Grad-CAM)\n",
    "\n",
    "https://qiita.com/bele_m/items/a7bb15313e2a52d68865"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- configurations --#\n",
    "num_dat = 20 # number of snapshot\n",
    "nx = 384 # number of grids in x direction\n",
    "ny = 192 # number of grids in y direction\n",
    "\n",
    "#-- load coordinates --#\n",
    "df = pd.read_csv('./Xcor',header=None,delim_whitespace=True)\n",
    "dataset = df.values\n",
    "xca = dataset[9:393,1]\n",
    "\n",
    "df = pd.read_csv('./Ycor',header=None,delim_whitespace=True)\n",
    "dataset = df.values\n",
    "yca = dataset[4:196,1]\n",
    "\n",
    "#-- data load --#\n",
    "omega = np.zeros((num_dat,nx,ny,1))\n",
    "for nt in range(num_dat):\n",
    "    omega[nt,:,:,0] = np.loadtxt('./omg_dat-'+'{0:02d}'.format(nt)+'.csv',delimiter=',')\n",
    "\n",
    "cd = np.loadtxt('./cd_dat.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 384, 192, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 384, 192, 32)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 192, 96, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 192, 96, 32)       25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 96, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 96, 48, 16)        12816     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 48, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 48, 24, 16)        6416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 24, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)           (None, 24, 12, 8)         1160      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 197,161\n",
      "Trainable params: 197,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#-- model load --#\n",
    "model = load_model('model.hdf5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.64it/s]\n"
     ]
    }
   ],
   "source": [
    "#-- define Grad-CAM function --#\n",
    "def grad_cam(model, layer_name, input_data):\n",
    "    \n",
    "    '''\n",
    "    This function requires\n",
    "    1. model: which is already trained\n",
    "    2. layer_name: Name of the target layer to calculate gradient\n",
    "    3. input_data: Input data in size of the input of the model\n",
    "    \n",
    "    and returns visualization of feature intensity at the target layer\n",
    "    '''\n",
    "    convout_tensor = model.get_layer(layer_name).output  # output of the target convolution layer/Tensor\n",
    "\n",
    "    grad_tensor = K.gradients(model.output, convout_tensor)[0] # gradient among convout_tensor and model.output/Tensor\n",
    "    grad_func = K.function([model.input], [convout_tensor, grad_tensor]) # a function to calculate the gradient\n",
    "\n",
    "    convout_val, grads_val = grad_func([input_data])\n",
    "    convout_val, grads_val = convout_val[0], grads_val[0]\n",
    "\n",
    "    weights = np.mean(grads_val, axis=(0,1))  # mean weights per each channel\n",
    "    grad_cam = np.dot(convout_val, weights)  # output of the target layer is weighted\n",
    "    grad_cam = np.maximum(grad_cam, 0) # ReLU\n",
    "    grad_cam = cv2.resize(grad_cam, (ny, nx), cv2.INTER_LINEAR)  # Resize\n",
    "    return grad_cam\n",
    "\n",
    "\n",
    "#-- calculate Grad-CAM at each instanteneous snapshots --#\n",
    "omega_inst = np.zeros((1,nx,ny,1)) # instanteneous snapshot of input vorticity field\n",
    "grad_cam_map = np.zeros((num_dat,nx,ny))\n",
    "\n",
    "for nt in tqdm(range(num_dat)):\n",
    "    omega_inst[0,:,:,:] = omega[nt,:,:,:]\n",
    "    grad_cam_map[nt,:,:] = grad_cam(model, \"conv2d_5\", omega_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
